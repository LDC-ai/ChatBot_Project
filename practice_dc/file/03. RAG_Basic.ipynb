{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6b82288e",
      "metadata": {
        "id": "6b82288e"
      },
      "source": [
        "### RAG 기본 구조 이해하기\n",
        "\n",
        "1. 사전작업(Pre-processing): 데이터 소스를 Vector DB (저장소) 에 문서를 로드-분할-임베딩-저장 \n",
        "\n",
        "- 1단계 문서로드(Document Load): 문서 내용을 불러옴\n",
        "- 2단계 분할(Text Split): 문서를 특정 기준(Chunk) 으로 분할\n",
        "- 3단계 임베딩(Embedding): 분할된(Chunk) 를 임베딩하여 저장\n",
        "- 4단계 벡터DB 저장: 임베딩된 Chunk 를 DB에 저장\n",
        "\n",
        "2. RAG 수행(RunTime) - 5~8 단계\n",
        "\n",
        "- 5단계 검색기(Retriever): 쿼리(Query) 를 바탕으로 DB에서 검색하여 결과를 가져오기 위하여 리트리버를 정의\n",
        "- 6단계 프롬프트: RAG 를 수행하기 위한 프롬프트를 생성. 프롬프트의 context 에는 문서에서 검색된 내용이 입력됨. 프롬프트 엔지니어링을 통하여 답변의 형식을 지정 가능\n",
        "- 7단계 LLM: 모델을 정의 (GPT-3.5, GPT-4, Claude, etc..)\n",
        "- 8단계 Chain: 프롬프트 - LLM - 출력 에 이르는 체인을 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c423a8",
      "metadata": {
        "id": "01c423a8"
      },
      "source": [
        "## 환경설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac5cb321",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -U langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sg4cuF6Ip9Ep",
      "metadata": {
        "id": "Sg4cuF6Ip9Ep"
      },
      "outputs": [],
      "source": [
        "!pip install langsmith python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "lOCXQe4xtHPn",
      "metadata": {
        "id": "lOCXQe4xtHPn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# API 키 정보 로드\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "34687156",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[API KEY]\n",
            "sk-l0rAOwEsqXqeXoZsj4jppfpH52TOFQezaNohE3ztURT3BlbkFJmqnZl5n_izzgDQoGAxMjXYm0nj4BrEzXWrArHJABUA\n",
            "[LANGCHAIN_PROJECT]\n",
            "LAG_Test\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LAG_Test'\n",
        "print(f\"[LANGCHAIN_PROJECT]\\n{os.environ['LANGCHAIN_PROJECT']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a224fd32",
      "metadata": {
        "id": "a224fd32"
      },
      "source": [
        "API KEY 를 설정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zgNuMaDGp_om",
      "metadata": {
        "collapsed": true,
        "id": "zgNuMaDGp_om"
      },
      "outputs": [],
      "source": [
        "pip install langchain-teddynote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "nGKuTxtsqmp9",
      "metadata": {
        "id": "nGKuTxtsqmp9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith 추적을 시작합니다.\n",
            "[프로젝트명]\n",
            "RAG_Test\n"
          ]
        }
      ],
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# 프로젝트 이름을 입력합니다.\n",
        "logging.langsmith(\"RAG_Test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0024d0c5",
      "metadata": {
        "id": "0024d0c5"
      },
      "source": [
        "[LangSmith](https://smith.langchain.com)를 사용하여 체인이나 에이전트 내부에서 정확히 무슨 일이 일어나고 있는지 조사 가능\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2de11a49",
      "metadata": {
        "id": "2de11a49"
      },
      "source": [
        "## 네이버 뉴스 기반 QA(Question-Answering) 챗봇\n",
        "\n",
        "네이버 뉴스기사의 내용에 대해 질문할 수 있는 **뉴스기사 QA 앱** 을 구축할 것입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "puiooOMMlebQ",
      "metadata": {
        "collapsed": true,
        "id": "puiooOMMlebQ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sbOVchN5rNmI",
      "metadata": {
        "collapsed": true,
        "id": "sbOVchN5rNmI"
      },
      "outputs": [],
      "source": [
        "### PDF 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# PDF 파일 로드. 파일의 경로 입력\n",
        "loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
        "\n",
        "# 페이지 별 문서 로드\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "db57b978",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/elicer/Langchain실습 코드\n",
            "문서의 수: 891\n",
            "\n",
            "[페이지내용]\n",
            "PassengerId: 11\n",
            "Survived: 1\n",
            "Pclass: 3\n",
            "Name: Sandstrom, Miss. Marguerite Rut\n",
            "Sex: female\n",
            "Age: 4\n",
            "SibSp: 1\n",
            "Parch: 1\n",
            "Ticket: PP 9549\n",
            "Fare: 16.7\n",
            "Cabin: G6\n",
            "Embarked: S\n",
            "\n",
            "[metadata]\n",
            "{'source': '../titanic/train.csv', 'row': 10}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### csv 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "import os\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "# CSV 파일 로드\n",
        "loader = CSVLoader(file_path=\"../titanic/train.csv\")\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06dcdabf",
      "metadata": {},
      "outputs": [],
      "source": [
        "### 폴더 내의 모든 파일 로드하여 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"data/*.txt\", show_progress=True)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[0].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")\n",
        "\n",
        "\n",
        "### 폴더 내의 모든 pdf 로드하여 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"data/*.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\\n\")\n",
        "print(\"[메타데이터]\\n\")\n",
        "print(docs[0].metadata)\n",
        "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
        "print(docs[0].page_content[2500:3000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473655b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Python 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import PythonLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"**/*.py\", loader_cls=PythonLoader)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\\n\")\n",
        "print(\"[메타데이터]\\n\")\n",
        "print(docs[0].metadata)\n",
        "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
        "print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8435e8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "### txt 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"data/appendix-keywords.txt\")\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[0].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
            "Successfully installed beautifulsoup4-4.12.3 bs4-0.0.2 soupsieve-2.6\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.2-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (0.1.134)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (3.10.10)\n",
            "Requirement already satisfied: requests<3,>=2 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (0.3.10)\n",
            "Requirement already satisfied: numpy<2,>=1 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.3 in /home/elicer/.local/lib/python3.10/site-packages (from langchain_community) (0.3.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/elicer/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/elicer/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/elicer/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/elicer/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/elicer/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/elicer/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.15.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/elicer/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/elicer/.local/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/elicer/.local/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.3->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /home/elicer/.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /home/elicer/.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/elicer/.local/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/elicer/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/elicer/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/elicer/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /home/elicer/.local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/elicer/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/elicer/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/elicer/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/elicer/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/elicer/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: httpcore==1.* in /home/elicer/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: anyio in /home/elicer/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2)\n",
            "Requirement already satisfied: sniffio in /home/elicer/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/elicer/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/elicer/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /home/elicer/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain_community) (2.23.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/elicer/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain_community) (0.7.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/elicer/.local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/elicer/.local/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.2 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f3d1b0fc",
      "metadata": {
        "id": "f3d1b0fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "LPaLNIrHsTF5",
      "metadata": {
        "id": "LPaLNIrHsTF5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /home/elicer/.local/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /home/elicer/.local/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /home/elicer/.local/lib/python3.10/site-packages (from faiss-cpu) (24.1)\n",
            "Installing collected packages: pypdf, faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0 pypdf-5.0.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "Successfully installed pip-24.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9f69f249",
      "metadata": {
        "id": "9f69f249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문서의 수: 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://n.news.naver.com/article/296/0000082139'}, page_content='\\n\"애벌레처럼 뭘 입는거야?\"...몸 압박해 꿀잠 잔다? 뭔가 봤더니\\n\\n\\n틱톡에서 유행 중인 \\'어른 포대기\\'...머리부터 발끝까지 감싸고, 태아 자세로 누운 채로 애벌레처럼 뒹굴면 잠 잘온다 주장\\n\\n\\n\\n천으로 몸을 감싼 후 잠자리에 드는 새로운 수면법이 트렌드로 떠오르고 있다. 맨 오른쪽=일본의 전통 치료법인 \\'오토나마키\\' [사진=영국 일간 데일리메일 보도 갈무리]잠 잘자는 묘책, 애벌레가 되어라?  천으로 몸을 감싼 후 잠자리에 드는 새로운 수면법이 트렌드로 떠오르고 있다. 아기를 천에 감싸는 것처럼 자신의 몸을 감싸는 방식으로 마치 애벌레를 연상케 한다.  틱톡에서는 신축성 있는 천에 몸을 구겨 넣고 잠자리에 드는 장면을 어렵지 않게 찾을 수 있다. 이렇게 몸을 감싸고 자면 불안 완화, 자세 개선, 깊은 수면 등 건강상의 이점을 제공한다는 것이 이들의 주장이다. 머리부터 발끝까지 감싸고, 태아 자세로 누운 채 부드럽게 흔들리거나 굴러다니면 잠을 잘 자게 돕는다는 것.  이 트렌드를 옹호하는 사람들은 몸을 천으로 감싸는 자체가 피부 깊숙한 층의 촉각 수용체를 자극해 긴장을 풀어준다고 입을 모은다. 실제로 특정 신경 세포가 활성화되면 평온한 느낌을 촉진하는 것으로 알려져 있긴하다. 한 여성은 이 자세를 통해 오랜 불면증을 해결했다고 주장했다.  실상 이 아이디어는 일본의 전통 치료법인 \\'오토나마키\\'에서 유래된 것으로 여겨진다는 것이 전문가들의 설명이다. 오토나마키는 직역하면 \\'어른 포대기\\'로, 사람들이 머리부터 발끝까지 큰 천으로 감싸는 방법이다. 원래 산후 재활 치료의 일환으로 개발됐다. 출산 후 산모의 신체 유연성 개선과 근육 이완, 관절 통증 완화 목적에서 일반적인 신체적 긴장 완화 및 유연성 개선을 위한 방법으로 그 개념이 확장됐다.  \\'어른 포대기\\'는 \\'깊은 압박 터치(DTP, Deep Touch Pressure)\\' 원칙에 따른다. 단순한 무게가 아니라 부드럽지만 깊은 압박을 통해 몸에 전달되는 촉각 자극을 의미한다. 이 DTP는 신경과학자인 진 아이레스가 1970년대에 제시한 감각 통합 이론(Sensory Integration Theory)에서 기인한다. 신체가 외부 자극을 처리하고 그에 적절히 반응하는 방법을 연구한 이론으로, 깊은 압박 터치가 특정 신경계 반응을 유도해 감각 과부하나 불안증을 완화하는 데 효과적이라는 사실을 밝혀냈다. DTP를 통해 심신을 안정시키고 감각 과민 반응을 조절하는 데 도움이 될 수 있음을 처음으로 시사한 연구였다.  DTP가 불면증을 해결한다는 과학적 증거 아직 없어   미국 버지니아 커먼웰스 대학의 DTP 전문가인 스테이시 레이놀드 박사는 뉴욕 타임스에 \"터치와 각성의 연관성은 잘 알려져 있다\"며 \"우리의 피부와 근육, 관절 주변에는 가벼운 터치나 더 깊은 터치에 반응하는 수용체들이 있다\"고 설명했다. 가벼운 터치, 예를 들어 간지럼이나 피부 위를 벌레가 기어가는 듯한 감각은 주로 경계와 각성을 유발하는 반면, 깊은 터치 수용체는 더 진정된 효과를 유발하는 경향이 있다는 것이다.  다만 스테이시 박사는 \"이 DTP가 불면증을 해결 할 만큼의 과학적 증거는 아직 없다\"며 \"실제로 밤에 더 나은 수면을 돕는지 여부는 확인되지 않았다\"고 말했다. 소규모 연구에서 무거운 담요, 즉 더 밀도가 높은 충전재가 있는 담요가 더 편안한 밤잠을 돕는 데 도움이 될 수 있다는 일부 증거가 있을 뿐이다.  2020년 연구 리뷰에 따르면 무거운 담요를 사용하는 것이 불안감을 완화하는 데 도움을 준다. 무거운 담요 아래에 누워 있는 것은 포대기 천에 단단히 감싸이는 것과는 다르지만, 포대기로 인해 움직일 수 없는 상태는 유사한 이완감을 줄 수 있다.  \\n\\n')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://n.news.naver.com/article/296/0000082139\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            \"div\",\n",
        "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b4d5bce",
      "metadata": {
        "id": "5b4d5bce"
      },
      "source": [
        "`RecursiveCharacterTextSplitter`는 문서를 지정된 크기의 청크로 나눔\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8e9bf670",
      "metadata": {
        "id": "8e9bf670"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a38783",
      "metadata": {
        "id": "49a38783"
      },
      "source": [
        "`FAISS` 혹은 `Chroma`와 같은 vectorstore는 이러한 청크를 바탕으로 문서의 벡터 표현을 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "62a8ca04",
      "metadata": {
        "id": "62a8ca04"
      },
      "outputs": [],
      "source": [
        "# 벡터스토어를 생성합니다.\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a89f55",
      "metadata": {
        "id": "00a89f55"
      },
      "source": [
        "`vectorstore.as_retriever()`를 통해 생성된 검색기는 프롬프트와 `ChatOpenAI` 모델을 사용하여 새로운 내용을 생성\n",
        "\n",
        "`StrOutputParser`는 생성된 결과를 문자열로 파싱\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a59f677c",
      "metadata": {
        "id": "a59f677c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
        "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
        "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6d16128d",
      "metadata": {
        "id": "6d16128d"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "\n",
        "# 체인을 생성합니다.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9370eb",
      "metadata": {
        "id": "be9370eb"
      },
      "source": [
        "스트리밍 출력을 위하여 `stream_response` 를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "78fed977",
      "metadata": {
        "id": "78fed977"
      },
      "outputs": [],
      "source": [
        "from langchain_teddynote.messages import stream_response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4948a029",
      "metadata": {
        "id": "4948a029"
      },
      "source": [
        "\n",
        "\n",
        "> [LangSmith Trace](https://smith.langchain.com/o/e738ca73-da9f-5fcd-86bb-d729db658172)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "78275b37",
      "metadata": {
        "id": "78275b37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "새로운 수면법으로는 천으로 몸을 감싸고 잠자리에 드는 방법이 있습니다. 이 방법은 일본의 전통 치료법인 '오토나마키'에서 유래된 것으로, 머리부터 발끝까지 큰 천으로 몸을 감싸고 태아 자세로 누워 부드럽게 흔들리거나 굴러다니는 방식입니다. 이 수면법은 불안 완화, 자세 개선, 깊은 수면 등의 건강상의 이점을 제공한다고 주장됩니다. 또한, 몸을 천으로 감싸는 것이 피부 깊숙한 층의 촉각 수용체를 자극해 긴장을 풀어준다고 알려져 있습니다."
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"새로운 수면법을 알려줘..\")\n",
        "# # 제너레이터에서 데이터를 하나씩 모아서 문자열로 합치기\n",
        "# answer_content = ''.join([chunk for chunk in answer])\n",
        "\n",
        "# # 결과 출력\n",
        "# print(answer_content)\n",
        "stream_response(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "93c96f34",
      "metadata": {
        "id": "93c96f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "새로운 수면법은 천으로 몸을 감싸고 잠자리에 드는 방식으로, 이는 일본의 전통 치료법인 '오토나마키'에서 유래된 것으로 여겨집니다. 이 방법은 몸을 감싸는 것이 피부 깊숙한 층의 촉각 수용체를 자극하여 긴장을 풀어주고, 불안 완화, 자세 개선, 깊은 수면 등의 건강상의 이점을 제공한다고 주장합니다. \n",
            "\n",
            "영어로 번역하면 다음과 같습니다:\n",
            "\n",
            "\"A new sleeping method involves wrapping the body in fabric before going to bed, which is believed to have originated from the Japanese traditional therapy called 'otonamaki'. This method claims to provide health benefits such as anxiety relief, posture improvement, and deep sleep by stimulating the tactile receptors deep within the skin, helping to relax the body.\""
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"뉴스기사의 새로운 수면법을 찾아서 이를 영어로 번역해줘.\")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6fd1f686",
      "metadata": {
        "id": "6fd1f686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- 천으로 몸을 감싸고 잠자리에 드는 새로운 수면법\n",
            "- 아기를 천에 감싸는 방식과 유사하게 자신의 몸을 감싸는 방법\n",
            "- 틱톡에서 신축성 있는 천에 몸을 구겨 넣고 자는 장면이 유행\n",
            "- 건강상의 이점: 불안 완화, 자세 개선, 깊은 수면\n",
            "- 머리부터 발끝까지 감싸고 태아 자세로 누워 부드럽게 흔들리거나 굴러다니는 방식\n",
            "- 피부 깊숙한 층의 촉각 수용체 자극으로 긴장 완화\n",
            "- 일본의 전통 치료법 '오토나마키'에서 유래\n",
            "- '깊은 압박 터치(DTP)' 원칙에 기반\n",
            "- DTP는 신경과학에서 감각 과부하나 불안증 완화에 효과적이라는 연구 결과가 있음\n",
            "- 그러나 DTP가 불면증을 해결한다는 과학적 증거는 아직 없음"
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"새로운 수면 법을 bullet points 형식으로 작성해 주세요.\")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f507cd6b",
      "metadata": {
        "id": "f507cd6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다."
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"삼성전자 임직원 숫자는 몇명인가요?\")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "주어진 데이터는 타이타닉 호의 승객 정보로 보입니다. 각 승객에 대한 정보는 다음과 같습니다:\n",
            "\n",
            "1. **승객 ID (PassengerId)**: 각 승객을 식별하는 고유 번호.\n",
            "2. **생존 여부 (Survived)**: 1은 생존, 0은 사망을 나타냅니다.\n",
            "3. **객실 등급 (Pclass)**: 승객의 객실 등급으로, 1, 2, 3으로 나뉘며, 1이 가장 높은 등급입니다.\n",
            "4. **이름 (Name)**: 승객의 이름.\n",
            "5. **성별 (Sex)**: 승객의 성별.\n",
            "6. **나이 (Age)**: 승객의 나이.\n",
            "7. **형제/자매 수 (SibSp)**: 승객과 함께 탑승한 형제 또는 자매의 수.\n",
            "8. **부모/자녀 수 (Parch)**: 승객과 함께 탑승한 부모 또는 자녀의 수.\n",
            "9. **티켓 번호 (Ticket)**: 승객의 티켓 번호.\n",
            "10. **요금 (Fare)**: 승객이 지불한 요금.\n",
            "11. **객실 번호 (Cabin)**: 승객이 배정받은 객실 번호.\n",
            "12. **탑승 항구 (Embarked)**: 승객이 탑승한 항구.\n",
            "\n",
            "제공된 데이터에서 승객 4명의 정보가 포함되어 있으며, 이 중 2명은 생존하고 2명은 사망한 것으로 나타납니다. 객실 등급은 모두 3등급이며, 성별은 모두 남성입니다. 나이는 21세에서 31세 사이입니다."
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"해당 데이터를 분석해줘\")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다."
          ]
        }
      ],
      "source": [
        "answer = rag_chain.stream(\"데이터가 4개 밖에 없나\")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
